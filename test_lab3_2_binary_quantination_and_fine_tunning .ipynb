{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from models_cifar100.resnet import ResNet18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hparam_bestvalue: {'epochs': 100, 'initial_lr': 0.001}\n",
      "best_test_accuracy 91.27\n"
     ]
    }
   ],
   "source": [
    "# We load the dictionary\n",
    "path1 = 'Session1_lab2_Resnet18_cifar10.pth'\n",
    "# loaded_cpt = torch.load(path1)\n",
    "loaded_cpt = torch.load(path1, map_location=torch.device('cpu'))\n",
    "# Fetch the hyperparam value\n",
    "hparam_bestvalue = loaded_cpt['hyperparam']\n",
    "print('hparam_bestvalue:', hparam_bestvalue)\n",
    "# accuracy\n",
    "print(\"best_test_accuracy\",loaded_cpt['final_test_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "  )\n",
       "  (linear): Linear(in_features=512, out_features=100, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# construct the model\n",
    "model_1 = ResNet18()\n",
    "\n",
    "# Load the model state dictionary with the loaded state dict\n",
    "model_1.load_state_dict(loaded_cpt['net'])\n",
    "\n",
    "# If you use this model for inference (= no further training), you need to set it into eval mode\n",
    "model_1.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perform binary quantination\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize the BC class\n",
    "from binaryconnect import BC\n",
    "bc = BC(model_1)\n",
    "# Apply binary quantization\n",
    "bc.binarization()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the quantized model\n",
    "# torch.save(bc.model.state_dict(), 'Session2_lab1_Resnet18_cifar10_binnary.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# test quantinazed model performance "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.datasets import CIFAR10\n",
    "import torchvision.transforms as transforms\n",
    "import torch\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "import torch.nn as nn\n",
    "from models_cifar100.resnet import ResNet18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "CUDA is available. Using GPU.\n"
     ]
    }
   ],
   "source": [
    "# Load the CIFAR-10 dataset\n",
    "## Normalization adapted for CIFAR10\n",
    "normalize_scratch = transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n",
    "# Transforms is a list of transformations applied on the 'raw' dataset before the data is fed to the network. \n",
    "# Here, Data augmentation (RandomCrop and Horizontal Flip) are applied to each batch, differently at each epoch, on the training set data only\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    normalize_scratch,\n",
    "])\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    normalize_scratch,\n",
    "])\n",
    "### The data from CIFAR10 will be downloaded in the following folder\n",
    "rootdir = './data/cifar10'\n",
    "# Load the CIFAR-10 dataset\n",
    "c10train = CIFAR10(rootdir,train=True,download=True,transform=transform_train)\n",
    "c10test = CIFAR10(rootdir,train=False,download=True,transform=transform_test)\n",
    "# Create DataLoaders\n",
    "trainloader = DataLoader(c10train,batch_size=32,shuffle=True)\n",
    "testloader = DataLoader(c10test,batch_size=32)\n",
    "\n",
    "# device check\n",
    "if torch.cuda.is_available():\n",
    "    print(\"CUDA is available. Using GPU.\")\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    print(\"CUDA is not available. Using CPU.\")\n",
    "    device = torch.device(\"cpu\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 62.43%\n"
     ]
    }
   ],
   "source": [
    "# Load the quantized model\n",
    "model_2 = ResNet18()\n",
    "path2 = 'Session2_lab1_Resnet18_cifar10_binnary.pth'\n",
    "model_2.load_state_dict(torch.load(path2))\n",
    "model_2.to(device)\n",
    "\n",
    "# test the model on the test set\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = model_2(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "test_accuracy = 100 * correct / total\n",
    "print(f'Test Accuracy: {test_accuracy:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Model Memory: 42.80 MB\n",
      "Quantized Model Memory: 1.34 MB\n"
     ]
    }
   ],
   "source": [
    "# Compute the memory usage\n",
    "# Assuming 32-bit floats for original and 1-bit for binary quantized model\n",
    "original_memory = original_params * 32  # in bits\n",
    "quantized_memory = quantized_params * 1  # in bits for binary quantization\n",
    "\n",
    "print(f\"Original Model Memory: {original_memory / 8 / 1024 ** 2:.2f} MB\")\n",
    "print(f\"Quantized Model Memory: {quantized_memory / 8 / 1024 ** 2:.2f} MB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Inference Time\n",
    "The time it takes for the model to make predictions can also be a measure of its complexity, particularly from an operational standpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def measure_inference_time(model, data_loader, device):\n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "    start_time = time.time()\n",
    "    with torch.no_grad():\n",
    "        for data, _ in data_loader:\n",
    "            data = data.to(device)\n",
    "            outputs = model(data)\n",
    "    end_time = time.time()\n",
    "    return end_time - start_time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Model Inference Time: 2.22 s\n",
      "Quantized Model Inference Time: 2.21 s\n"
     ]
    }
   ],
   "source": [
    "inference_time_original = measure_inference_time(model_1, testloader, device )\n",
    "print(f\"Original Model Inference Time: {inference_time_original:.2f} s\")\n",
    "inference_time_quantized = measure_inference_time(model_2, testloader, device )\n",
    "print(f\"Quantized Model Inference Time: {inference_time_quantized:.2f} s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inference_time_original = measure_inference_time(model_1, testloader, device = \"cpu\")\n",
    "# print(f\"Original Model Inference Time: {inference_time_original:.2f} s\")\n",
    "# inference_time_quantized = measure_inference_time(model_2, testloader, device = \"cpu\")\n",
    "# print(f\"Quantized Model Inference Time: {inference_time_quantized:.2f} s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# fin tunning the hyperparemeter after quantination "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "several strategies to recover the accuracy:\n",
    "\n",
    "Fine-Tuning: After applying binary quantization, you can fine-tune the quantized model on the training dataset. Even a few epochs of fine-tuning might help in recovering some of the lost accuracy.\n",
    "\n",
    "Hybrid Approaches: Instead of quantizing all layers to binary weights, you might consider a hybrid approach where only certain layers are quantized, or different quantization schemes (like ternary weights or lower-bit quantizations) are applied selectively.\n",
    "\n",
    "Quantization-Aware Training: Instead of applying quantization as a post-processing step, you can train the network with quantization in mind. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: Loss 0.04206761345267296\n",
      "Epoch 1: Loss 0.2428952157497406\n",
      "Epoch 2: Loss 0.004120262339711189\n",
      "Epoch 3: Loss 0.0010275698732584715\n",
      "Epoch 4: Loss 0.00659582344815135\n",
      "Epoch 5: Loss 0.0070841507986187935\n",
      "Epoch 6: Loss 0.08025392144918442\n",
      "Epoch 7: Loss 0.018089229241013527\n",
      "Epoch 8: Loss 0.045258451253175735\n",
      "Epoch 9: Loss 0.025238467380404472\n",
      "Epoch 10: Loss 0.053677886724472046\n",
      "Epoch 11: Loss 0.0006212434382177889\n",
      "Epoch 12: Loss 0.006726369261741638\n",
      "Epoch 13: Loss 0.004015504848212004\n",
      "Epoch 14: Loss 0.2850176692008972\n",
      "Epoch 15: Loss 0.001490758964791894\n",
      "Epoch 16: Loss 0.0038603274151682854\n",
      "Epoch 17: Loss 0.14339271187782288\n",
      "Epoch 18: Loss 0.13537806272506714\n",
      "Epoch 19: Loss 0.002384340390563011\n",
      "Epoch 20: Loss 0.007040188182145357\n",
      "Epoch 21: Loss 0.1538671851158142\n",
      "Epoch 22: Loss 0.01756676286458969\n",
      "Epoch 23: Loss 0.04192166030406952\n",
      "Epoch 24: Loss 0.004998200573027134\n",
      "Epoch 25: Loss 0.007983146235346794\n",
      "Epoch 26: Loss 0.017243223264813423\n",
      "Epoch 27: Loss 0.0010289873462170362\n",
      "Epoch 28: Loss 0.0001419628970324993\n",
      "Epoch 29: Loss 0.00786653347313404\n",
      "Epoch 30: Loss 0.3483163118362427\n",
      "Epoch 31: Loss 0.19264225661754608\n",
      "Epoch 32: Loss 0.2292182743549347\n",
      "Epoch 33: Loss 0.0013322115410119295\n",
      "Epoch 34: Loss 0.0010431939736008644\n",
      "Epoch 35: Loss 0.21492359042167664\n",
      "Epoch 36: Loss 0.009119957685470581\n",
      "Epoch 37: Loss 0.13131839036941528\n",
      "Epoch 38: Loss 0.00021940923761576414\n",
      "Epoch 39: Loss 0.0017128633335232735\n",
      "Epoch 40: Loss 0.00016000584582798183\n",
      "Epoch 41: Loss 0.0007528269779868424\n",
      "Epoch 42: Loss 0.005642781965434551\n",
      "Epoch 43: Loss 8.630527008790523e-05\n",
      "Epoch 44: Loss 0.0015075443079695106\n",
      "Epoch 45: Loss 0.0013549469877034426\n",
      "Epoch 46: Loss 0.06416793167591095\n",
      "Epoch 47: Loss 0.00010084905079565942\n",
      "Epoch 48: Loss 0.0045033348724246025\n",
      "Epoch 49: Loss 0.007161293178796768\n",
      "Finished fine-tuning\n",
      "Model saved\n"
     ]
    }
   ],
   "source": [
    "# fine-tune a binary quantized model in PyTorch\n",
    "model_2.train()\n",
    "optimizer = torch.optim.Adam(model_2.parameters(), lr=0.001)  # Using a lower learning rate for fine-tuning\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "num_fine_tune_epochs = 50\n",
    "# Fine-tuning loop\n",
    "\n",
    "# train loop\n",
    "for epoch in range(num_fine_tune_epochs):\n",
    "    for data, target in trainloader:\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model_2(data)\n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    print(f'Epoch {epoch}: Loss {loss.item()}')\n",
    "\n",
    "print('Finished fine-tuning')\n",
    "\n",
    "# save the model \n",
    "torch.save({\n",
    "    'net': model_2.state_dict(),\n",
    "    'final_test_accuracy': test_accuracy,\n",
    "    'hyperparam': hparam_bestvalue,\n",
    "}, 'Session2_lab1_Resnet18_cifar10_binnary_tunning_2.pth')\n",
    "print('Model saved')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 91.70%\n"
     ]
    }
   ],
   "source": [
    "# load the model\n",
    "path3 = 'Session2_lab1_Resnet18_cifar10_binnary_tunning_2.pth'\n",
    "loaded_cpt = torch.load(path3)\n",
    "\n",
    "# construct the model\n",
    "model_3 = ResNet18()\n",
    "# Load the model state dictionary with the loaded state dict\n",
    "model_3.load_state_dict(loaded_cpt['net'])\n",
    "model_3.eval().to(device)\n",
    "\n",
    "# test the model on the test set\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = model_3(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "test_accuracy = 100 * correct / total\n",
    "print(f'Test Accuracy: {test_accuracy:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantized Model after tunning Inference Time: 2.38 s\n"
     ]
    }
   ],
   "source": [
    "inference_time_quantized = measure_inference_time(model_3, testloader, device )\n",
    "print(f\"Quantized Model after tunning Inference Time: {inference_time_quantized:.2f} s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 88.51%\n"
     ]
    }
   ],
   "source": [
    "# save the model \n",
    "torch.save({\n",
    "    'net': model_2.state_dict(),\n",
    "    'final_test_accuracy': test_accuracy,\n",
    "    'hyperparam': hparam_bestvalue,\n",
    "}, 'Session2_lab1_Resnet18_cifar10_binnary_tunning_1.pth')\n",
    "\n",
    "# test the model on the test set\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = model_2(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "test_accuracy = 100 * correct / total\n",
    "print(f'Test Accuracy: {test_accuracy:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original model size: 42.88 MB\n",
      "Quantized model size: 42.88 MB\n",
      "Tuned quantized model (10 epochs) size: 42.88 MB\n",
      "Tuned quantized model (50 epochs) size: 42.88 MB\n"
     ]
    }
   ],
   "source": [
    "path4 = \"Session2_lab1_Resnet18_cifar10_binnary_tunning_1.pth\"\n",
    "import os\n",
    "\n",
    "original = path1\n",
    "quantized = path2\n",
    "tuned_quantized_10= path4\n",
    "tuned_quantized_50 = path3\n",
    "\n",
    "# Function to convert bytes to megabytes\n",
    "def bytes_to_mb(size_in_bytes):\n",
    "    return size_in_bytes / 1024 / 1024\n",
    "\n",
    "# Measure the file sizes\n",
    "original_size = os.path.getsize(original)\n",
    "quantized_size = os.path.getsize(quantized)\n",
    "tuned_quantized_10_size = os.path.getsize(tuned_quantized_10)\n",
    "tuned_quantized_50_size = os.path.getsize(tuned_quantized_50)\n",
    "\n",
    "print(f\"Original model size: {bytes_to_mb(original_size):.2f} MB\")\n",
    "print(f\"Quantized model size: {bytes_to_mb(quantized_size):.2f} MB\")\n",
    "print(f\"Tuned quantized model (10 epochs) size: {bytes_to_mb(tuned_quantized_10_size):.2f} MB\")\n",
    "print(f\"Tuned quantized model (50 epochs) size: {bytes_to_mb(tuned_quantized_50_size):.2f} MB\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
